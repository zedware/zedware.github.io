---
layout: post
title: Notes on deduplication
original: https://blog.csdn.net/zedware/article/details/6118892
tags: Dedup
---

Data de-duplication是存储中比较成熟的技术了。无论个人的桌面机，还是企业的服务器，或是备份用的存储系统中，都存在大量的重复数据。最简单的一种就是同一个文件存有多份，稍微复杂一点的是类似的文件存在多份。如果是备份系统，则数据的多次全备份之间更是存在着大量的荣誉数据，即便是多次增量备份或差分备份之间，也存在着很多的冗余数据。解决这些冗余数据，减少存储空间，提高恢复效率的办法有很多。最简单也最容易想到的是Single Instance Storage，也就是每个同样的文件仅仅保留一份，而不是重复保留。稍复杂的办法可以借鉴版本管理的办法，对于同一个文件的不同版本仅仅保存差异部分。更复杂的办法是识别不同文件/对象之间的重复部分，将其冗余消除，仅记录一份。不同文件或对象之间重复部分的识别比较复杂，又要保证速度，又要保证廉价，更要保证数据完整性。不过业界已经有了很多成熟的算法和产品，例如Data
 Domain。
压缩其实就是一种去除数据重复的办法，只不过压缩的粒度偏小，大家不把它当做典型的数据重复消除技术。从数据重复消除的不同层次看，也许可以将其分为几层：
1、语义最丰富的对象层。例如文件级、数据库级。可以充分利用应用掌握的语义来消除大粒度的冗余。不过这种办法要依赖于对这些对象格式的识别，做起来不那么容易，而且容易遇到不同版本格式的处理困难。
2、语义中等的对象层。例如数据块级、连续的数据段级。这种方法通用性较强，处理效率较高，比较适合企业级存储，特别是备份系统的重复数据消除。
3、语义最少的对象层。例如传统的数据压缩手段。这种方法的通用性最强，处理效率很高，算法很多，而且平均的压缩效果也比较好。
 
